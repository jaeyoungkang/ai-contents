---
id: 'Prompt-Engineering-2025-halfyear-gemini'
title: '대규모 언어 모델(LLM) 프롬프팅 기법 연구 보고서 (2025년 상반기 동향 중심)'
date: '2025-07-03'
author: 'Gemini Deep Research'
excerpt: 'LLM 프롬프팅은 모델의 잠재력을 최대한 활용하기 위해 명확하고 구체적인 지시를 제공하는 것이 핵심이며, CoT, RAG, 자기 수정, 다중 전문가 프롬프팅 등 다양한 고급 기법으로 발전했습니다. 2025년 상반기에는 프롬프트 최적화가 자동화되고 LLM의 신뢰성 및 안전성 확보에 중점을 두면서, LLM이 자율적이고 다목적인 시스템으로 진화하고 있습니다.'
category: '프롬프트 엔지니어링'
type: '반기 보고서'
---

# **대규모 언어 모델(LLM) 프롬프팅 기법 연구 보고서 (2025년 상반기 동향 중심)**

대규모 언어 모델(LLM)은 인공지능 분야에서 혁신적인 발전을 이끌며 다양한 응용 분야에서 핵심적인 역할을 수행하고 있습니다. 이러한 LLM의 잠재력을 최대한 활용하기 위해서는 모델에 대한 효과적인 지시, 즉 '프롬프팅'이 필수적입니다. 프롬프트 엔지니어링은 LLM의 출력을 최적화하고, 복잡한 작업을 수행하며, 모델의 한계를 극복하는 데 중요한 기술로 부상했습니다. 본 보고서는 2025년 상반기까지 알려진 LLM 프롬프팅의 주요 방법론과 최신 동향을 심층적으로 분석하고, 각 기법의 원리, 장점, 한계 및 실제 적용 사례를 포괄적으로 제시합니다. 또한, 프롬프트 엔지니어링의 발전이 LLM의 전반적인 성능과 신뢰성에 미치는 영향을 다각적으로 조명하며, 향후 발전 방향에 대한 제언을 포함합니다.

## **1\. LLM 프롬프팅의 기본 원칙 및 핵심 개념**

효과적인 LLM 프롬프팅은 단순히 질문을 던지는 것을 넘어, 모델이 원하는 결과를 정확하고 일관되게 생성하도록 체계적으로 안내하는 과정을 포함합니다. 이 과정에는 여러 가지 핵심 원칙이 적용됩니다.

프롬프트는 명확하고 구체적이어야 합니다. 모델이 모호함 없이 원하는 결과를 정확히 이해할 수 있도록 지시를 명확하게 표현하고, 필요한 세부 사항이나 매개변수를 포함하는 것이 중요합니다.1 예를 들어, "기후 변화에 대한 요약을 제공하라"와 같이 직접적인 명령형 문구를 사용하는 것이 "기후 변화에 대한 요약을 제공해 주시겠습니까?"와 같이 공손한 표현을 사용하는 것보다 모델과의 상호작용에서 더 효율적입니다.2

필요한 경우 맥락이나 배경 정보를 제공하여 모델이 고려해야 할 관련 세부 사항을 참조하도록 해야 합니다. 다중 턴 상호작용에서는 이전 프롬프트의 맥락을 유지하는 것이 중요합니다.1 또한, 모델이 생성할 응답의 대상 독자를 명시하면 출력이 적절한 이해 수준에 맞춰 조정됩니다. 예를 들어, "기계 학습 개념을 데이터 과학 전문가에게 설명하라" 또는 "기계 학습 개념을 고등학생에게 설명하라"와 같이 대상 독자를 지정할 수 있습니다.2

원하는 출력의 긍정적인 예시와 원치 않는 출력을 피하기 위한 부정적인 예시를 포함하여 모델을 안내할 수 있습니다.1 특정 요구 사항을 강조하기 위해 대조적인 예시를 사용하는 것도 효과적입니다.1 지시를 내릴 때는 "포함하라"와 같은 긍정적인 지시어를 사용하고, "잊지 마라"와 같은 부정적인 지시어는 피하는 것이 좋습니다.2

프롬프트는 간결하고 집중적이어야 합니다. 지나치게 길거나 복잡한 지침은 피하고, 충분한 정보를 제공하는 것과 간결성 사이의 균형을 맞추는 것이 중요합니다.1 프롬프트의 여러 섹션을 명확히 구분하기 위해

\#\#\#Instruction\#\#\# 또는 \#\#\#Example\#\#\#과 같은 특정 구분자를 사용할 수 있습니다.2

AI 모델의 기능과 한계를 이해하고, 모델의 강점을 활용하기 위해 다양한 프롬프트를 실험해야 합니다.1 프롬프트 변형에 따른 모델 출력을 정기적으로 평가하고, 관찰된 모델 동작에 따라 프롬프트를 조정하며, 사용자 피드백을 통해 프롬프트 효과를 높이는 것이 필수적입니다.1

프롬프트 프라이밍은 언어 모델의 동작을 유도하기 위해 초기 지침이나 맥락을 제공하는 것을 포함합니다.1 모델에 특정 역할을 부여하여 대화의 맥락을 강화할 수 있습니다. 예를 들어, "당신은 이제 전문 재무 고문이다. 초보자를 위한 어떤 투자 전략을 추천하겠는가?"와 같이 역할을 부여할 수 있습니다.2 복잡한 주제나 작업은 일련의 간단한 프롬프트로 분해하여 처리하는 것이 효과적입니다. 예를 들어, "먼저, 인공지능이 무엇인지 설명하라. 다음으로, AI, 머신러닝, 딥러닝의 차이점을 설명하라"와 같이 작업을 분해할 수 있습니다.2 프롬프트에 인센티브를 추가하거나 2, 지침 준수의 중요성을 전달하기 위해 "페널티를 받을 것이다"와 같은 결과를 명시할 수 있습니다.2 마지막으로, "자연스럽고 인간적인 방식으로 답변하라"와 같은 지시를 포함하여 모델이 더 자연스러운 응답을 생성하도록 유도할 수 있습니다.2

LLM 프롬프팅에서 프롬프트에 너무 많은 요구사항을 지정하는 것이 오히려 성능 저하를 초래할 수 있다는 점은 중요한 고려 사항입니다. 사용자나 개발자는 LLM이 특정 요구사항을 따르도록 하기 위해 가능한 한 많은 지침을 프롬프트에 포함하려는 경향이 있습니다. 이는 "더 많은 정보가 더 나은 결과를 낳는다"는 직관적인 가정에 기반합니다. 그러나 연구에 따르면, 모든 요구사항을 단순히 명시하는 전략은 LLM의 제한된 지시 준수 능력 때문에 효과적으로 작동하지 않습니다. 더 많은 요구사항을 지정할수록 LLM의 성능이 최대 19%까지 떨어질 수 있다는 보고가 있습니다.3 또한, 개발자 프롬프트가 종종 불완전하게 지정되어 LLM이 지정되지 않은 요구사항을 41.1%의 확률로 추측할 수 있지만, 이러한 동작은 안정적이지 않으며 모델 또는 프롬프트 변경 시 정확도가 20% 이상 떨어질 가능성이 2배 높습니다.3 특히, 19개의 요구사항을 함께 지정했을 때 GPT-4o의 평균 정확도는 85.0%로 떨어지고, Llama-3.3-70B-Instruct와 같은 소형 모델은 79.7%로 더욱 저조한 결과를 보였습니다.3

이러한 현상은 LLM이 한 번에 처리할 수 있는 지시의 복잡성과 양에 내재적인 한계가 있음을 시사합니다. 너무 많은 지시가 주어지면, 모델은 중요한 지시를 간과하거나, 지시들 간의 미묘한 충돌을 해결하지 못하여 전반적인 성능이 저하될 수 있습니다. 이는 인간이 여러 가지 복잡한 지시를 동시에 받을 때 인지 부하가 증가하여 실수가 늘어나는 것과 유사한 원리입니다. 특정 요구사항(예: "교통수단 이용 가능성 언급" 또는 "유추 및 예시 사용")의 경우, 명확한 충돌이 없음에도 불구하고 정확도가 크게 떨어지는 현상이 관찰되었습니다.3 이는 프롬프트 엔지니어링이 단순히 "더 많이 말하는 것"이 아니라, "무엇을, 어떻게, 그리고 얼마만큼 말할 것인가"에 대한 전략적인 접근이 필요하다는 것을 의미합니다. 특히, 모델이 기본적으로 잘 따르는 요구사항에 대해서는 의도적으로 명시하지 않거나, 핵심적인 소수의 요구사항에 집중하여 프롬프트를 간결하게 유지하는 '의도적 불완전 지정'이 효과적인 전략이 될 수 있습니다.3 이는 프롬프트 최적화의 새로운 방향을 제시합니다.

## **2\. 주요 LLM 프롬프팅 기법 심층 분석**

LLM 프롬프팅은 단순한 지시를 넘어 복잡한 추론, 외부 지식 활용, 자체 개선 등 다양한 고급 기능을 가능하게 하는 여러 기법으로 발전했습니다.

### **2.1 제로샷 및 퓨샷 프롬프팅**

**정의 및 작동 방식**

* **제로샷 프롬프팅 (Zero-shot Prompting)**: 이 기법은 모델에게 어떠한 예시도 제공하지 않고, 오직 지시만으로 작업을 수행하도록 요청합니다. 모델은 사전 학습된 방대한 지식을 바탕으로 작업을 이해하고 응답을 생성합니다.5 이는 광범위한 데이터로 훈련된 LLM의 일반화 능력을 최대한 활용합니다.  
* **퓨샷 프롬프팅 (Few-shot Prompting)**: 프롬프트 내에 2\~5개의 소수 예시를 포함하여 모델이 원하는 동작을 학습하고 재현하도록 돕는 기법입니다. 이는 "인컨텍스트 학습(In-context Learning, ICL)"을 통해 모델이 패턴을 식별하고 새로운 입력에 효과적으로 적용하도록 합니다.5 모델은 제공된 예시들을 처리하여 숨겨진 패턴을 찾아내고, 이를 기반으로 유사하지만 이전에 보지 못한 작업에 대한 해결책을 추론합니다.10  
* **원샷 프롬프팅 (One-shot Prompting)**: 제로샷과 퓨샷의 중간 형태로, 단 하나의 예시를 제공하여 모델의 이해를 돕고 성능을 향상시킵니다.7 이는 기본적인 분류나 구조화된 정보 추출과 같이 특정 지침이 필요한 작업에 유용합니다.7

**장점 및 한계**

* **제로샷**: 레이블링된 데이터가 부족하거나 응답 속도가 중요할 때 특히 유용합니다. 모델이 예시 입력을 처리하거나 미세 조정할 필요가 없어 프롬프트 크기가 작고 지연 시간이 짧습니다.5 그러나 문구에 민감하여 작은 변화에도 출력에 큰 영향을 미칠 수 있습니다.5  
* **퓨샷**: 복잡한 작업에서 더 나은 정확도를 제공하며, 특히 대규모 모델에서 효과적입니다.5 새로운 작업에 대한 빠른 배포, 최소한의 데이터 수집 및 준비, 다양한 도메인 및 사용 사례에 대한 유연한 적용이 가능합니다.9 하지만 더 긴 프롬프트와 더 많은 토큰을 필요로 하여 계산 비용이 증가할 수 있고, 모델의 컨텍스트 창 크기에 제약을 받을 수 있습니다.5 복잡한 추론 작업에는 한계가 있으며, 단순히 예시를 추가하는 것만으로는 해결되지 않을 수 있습니다.9

**주요 적용 사례**

* **제로샷**: 번역, 요약, 콘텐츠 중재, 고객 피드백 분석, 스팸 감지, 소셜 미디어 감성 분석 등 사전 정의된 예시가 필요 없거나 즉각적인 응답이 중요한 작업에 적합합니다.5  
* **퓨샷**: 텍스트 분류, 감성 분석, 정보 추출 (이름, 나이, 직업 등), 질문 답변, 콘텐츠 생성 (특정 스타일의 글쓰기) 등 모델이 패턴을 인식하고 적용해야 하는 복잡한 작업에 유용합니다.7

**모범 사례 (퓨샷)**

* 프롬프트에 최소 2개에서 최대 5개의 예시를 포함하는 것이 일반적으로 권장됩니다. 너무 적은 예시는 충분한 맥락을 제공하지 못할 수 있고, 너무 많은 예시는 모델을 압도하거나 혼란스럽게 할 수 있습니다.9  
* 예시는 다양해야 하며, 긍정적 및 부정적 사례를 모두 포함하여 작업의 경계를 모델이 이해하도록 돕는 것이 중요합니다.9  
* 예시의 순서를 무작위로 하고 일관된 형식을 유지해야 모델이 패턴을 효과적으로 감지할 수 있습니다.9  
* Input: Output: 또는 INPUT/OUTPUT과 같은 명확한 구분자를 사용하여 예시와 실제 쿼리를 구분해야 합니다. 이 명확성은 모델이 요청을 올바르게 구별하는 데 도움이 됩니다.9  
* 초기에는 간단한 예시로 시작하고 필요에 따라 프롬프트 형식을 조정해야 합니다. 너무 일찍부터 복잡하게 만들지 않는 것이 좋습니다.9

퓨샷 프롬프팅의 효과는 단순히 예시의 양이 아닌, '질'과 '다양성'에 크게 좌우됩니다. 퓨샷 프롬프팅은 예시를 제공하여 모델의 성능을 향상시키므로, 더 많은 예시를 제공할수록 모델이 더 잘 학습할 것이라는 가정이 일반적일 수 있습니다. 그러나 퓨샷 프롬프팅의 품질은 '예시 선택(Example Selection)', '형식 일관성(Format Consistency)', '컨텍스트 창 관리(Context Window Management)'에 크게 의존합니다.9 특히, 효과적인 퓨샷 프롬프팅은 입력 예시의 양과 질 사이의 균형을 맞추는 데 달려 있습니다.10 너무 적은 예시는 충분한 맥락을 제공하지 못할 수 있고, 너무 많은 예시는 모델을 압도하거나 혼란스럽게 할 수 있습니다.9 또한, 예시는 다양해야 하고 긍정적 및 부정적 사례를 모두 포함하여 작업의 경계를 모델이 이해하도록 돕는 것이 권장됩니다.9 더 많은 예시가 항상 더 좋은 것은 아니며, 잘못된 순서는 모델을 혼란스럽게 할 수 있다는 점도 지적됩니다.9

이러한 현상은 LLM이 예시로부터 '패턴'을 식별하고 새로운 작업에 대한 해결책을 '추론'하는 능력을 활용하기 때문입니다.10 단순히 많은 예시를 나열하는 것은 모델이 과적합(overfitting)되거나, 컨텍스트 창의 한계로 인해 중요한 정보가 잘리거나 10, 오히려 혼란을 야기하여 일반화 능력을 저해할 수 있습니다. 반면, 소수라도 관련성 높고(Relevance) 10, 다양한(Diversity) 맥락을 포함하며 10, 일관된 형식(Format Consistency)의 예시를 제공하면, 모델은 더 견고하고 정확한 패턴을 학습하여 새로운 상황에 효과적으로 적용할 수 있습니다.9 퓨샷 프롬프팅의 성공은 '데이터 양'보다는 '데이터의 질과 전략적 구성'에 있음을 시사합니다. 이는 프롬프트 엔지니어링이 단순한 텍스트 입력이 아니라, 모델의 학습 메커니즘을 이해하고 그에 맞춰 최적의 학습 환경(in-context learning environment)을 조성하는 '미니 데이터셋 설계'에 가깝다는 점을 강조합니다. 따라서 퓨샷 프롬프팅을 활용할 때는 예시의 선정, 순서, 형식에 대한 깊이 있는 고려가 필수적입니다.

### **2.2 CoT (Chain-of-Thought) 프롬프팅**

**정의 및 메커니즘**

CoT 프롬프팅은 복잡한 다단계 추론 작업을 위해 LLM의 출력을 향상시키는 프롬프트 엔지니어링 기법입니다.11 이 기법은 모델이 논리적인 단계의 일관된 시리즈를 사용하여 단계별 추론 과정을 거치도록 안내함으로써 문제 해결을 용이하게 합니다.11 CoT는 LLM이 자연어로 "소리 내어 생각하는" 능력에서 영감을 받았으며, 모델 크기가 커질수록 추론 능력과 정확도가 증가하는 '이머전트 능력(emergent ability)'으로 간주됩니다.11

CoT의 메커니즘은 사용자가 일반적으로 프롬프트 끝에 "당신의 추론 단계를 설명하라" 또는 "답변을 단계별로 설명하라"와 같은 지시를 추가하여 모델이 결과뿐만 아니라 그 결과에 이르게 된 중간 단계들을 상세히 설명하도록 요청하는 방식으로 작동합니다.11 이는 LLM 에이전트가 추론을 일련의 단계로 분해하도록 돕습니다.12 예를 들어,

x^2 \- 5x \+ 6 \= 0과 같은 이차 방정식을 풀 때, CoT 프롬프팅은 LLM이 방정식을 표준 형식으로 식별하고, 계수를 결정하고, 이차 공식을 적용하고, 판별식을 계산하고, 최종적으로 x 값을 계산하는 일련의 논리적 단계를 거치도록 안내합니다.11

**성능 향상 효과**

CoT 프롬프팅은 복잡한 문제를 더 간단하고 관리하기 쉬운 단계로 분해하여 LLM이 정보를 더 효과적으로 관리하고 처리하도록 이끌어 응답의 정확성과 관련성을 높입니다.12 특히 수학 단어 문제 해결률을 표준 방법에 비해 300% 이상 향상시키는 것으로 나타났습니다 (GSM8K 벤치마크 기준).12 또한, 산술 추론, 상식 추론, 상징적 추론 등 다양한 벤치마크에서 상당한 정확도 향상을 가져옵니다.8

**CoT의 변형 및 활용 전략**

* **제로샷 CoT**: 단순히 "단계별로 생각해보자"와 같은 문구를 추가하는 것만으로도 복잡한 문제에 대한 CoT 추론을 유도할 수 있습니다.6  
* **CoT와 퓨샷 프롬프팅 결합**: 복잡한 작업의 경우, CoT와 퓨샷 프롬프팅을 결합하는 것이 특히 효과적일 수 있습니다.2  
* **CoT의 투명성**: CoT 프롬프팅의 투명성은 모델이 결론에 도달하는 과정을 개발자가 이해하는 데 도움을 주어 오류 식별 및 모델 개선에 기여합니다.12

CoT는 LLM의 '블랙박스'적 특성을 완화하고, '설명 가능한 AI(Explainable AI, XAI)'의 중요한 기반이 됩니다. LLM은 내부 작동 방식이 불투명한 '블랙박스' 모델로, 왜 특정 답변을 생성했는지 이해하기 어렵다는 비판을 받아왔습니다. 그러나 CoT 프롬프팅은 LLM을 "블랙박스에서 투명한 추론 기계로 전환시킨다"고 명확히 정의됩니다.12 이는 모델이 복잡한 작업을 더 간단한 단계로 분해하여, 사용자가 LLM이 응답에 도달하는 과정에 대한 '제어 및 통찰력'을 얻을 수 있게 해주기 때문입니다.12 CoT는 '중간 추론 단계'를 생성함으로써 모델이 결론에 도달하는 방식에 대한 '투명성과 이해'를 제공합니다.11

CoT는 모델이 최종 답변만 내놓는 것이 아니라, 그 답변에 이르는 논리적 과정을 명시적으로 보여주도록 강제합니다. 이 '단계별 설명'은 인간이 문제를 해결하는 방식과 유사하여, 모델의 내부 '사고 과정'을 외부화하고 가시화합니다. 이러한 가시화는 개발자가 모델의 오류를 식별하고 디버깅하는 데 결정적인 도움을 줍니다.12 또한, 사용자는 모델의 답변이 단순히 우연히 맞은 것이 아니라, 논리적인 근거를 가지고 있음을 확인할 수 있어 모델에 대한 신뢰도가 높아집니다. CoT는 단순히 LLM의 성능을 향상시키는 기술을 넘어, LLM의 '설명 가능성'을 높이는 근본적인 방법론입니다. 이는 특히 규제 준수, 법률 분석, 의료 진단 등 높은 신뢰성과 투명성이 요구되는 분야에서 LLM의 적용 가능성을 크게 확장시킵니다.12 CoT가 제공하는 추론 과정의 투명성은 LLM이 단순한 예측기가 아닌, '이해 가능한 지능'으로 인식될 수 있는 중요한 발판을 마련합니다.

### **2.3 RAG (Retrieval-Augmented Generation) 프롬프팅**

**정의 및 메커니즘**

RAG는 LLM의 출력을 최적화하기 위해, 모델의 학습 데이터 소스 외부에 있는 권위 있는 지식 기반을 참조하도록 하는 과정입니다.13 이 기법의 메커니즘은 다음과 같습니다. 먼저 사용자 쿼리를 분석하여 핵심 개념을 식별한 후 14, 검색 시스템이 외부 코퍼스(예: 인터넷, 도메인별 데이터베이스)에서 관련 문서를 검색합니다.13 이 검색된 정보는 LLM에 추가적인 맥락으로 제공되어, 모델이 새로운 지식과 기존 학습 데이터를 결합하여 더 나은 응답을 생성하도록 합니다.13 이 과정은 외부 데이터를 벡터 표현으로 변환하여 벡터 데이터베이스에 저장하고, 사용자 쿼리를 벡터 표현으로 변환하여 관련 정보를 검색하는 방식으로 이루어집니다.13

**주요 장점**

* **비용 효율성**: LLM을 특정 조직이나 도메인에 맞게 재학습(fine-tuning)하는 데 드는 높은 계산 및 재정적 비용을 줄여줍니다.13 RAG는 새로운 데이터를 LLM에 도입하는 더 비용 효율적인 접근 방식입니다.13  
* **최신 정보 제공**: LLM이 최신 연구, 통계, 뉴스 등 최신 정보를 활용할 수 있게 하여 응답의 관련성과 정확성을 유지할 수 있도록 합니다.13 LLM을 라이브 소셜 미디어 피드, 뉴스 사이트 또는 기타 자주 업데이트되는 정보 소스에 직접 연결할 수 있습니다.13  
* **사용자 신뢰도 향상**: LLM이 출처를 명시하고 인용할 수 있게 하여 정확한 정보를 제공하고 사용자 신뢰를 높입니다. 사용자는 필요에 따라 원본 문서를 직접 확인할 수도 있습니다.13  
* **개발자 제어력 강화**: 개발자가 LLM의 정보 소스를 제어하고 변경하여 변화하는 요구사항에 적응하거나 교차 기능 사용을 지원할 수 있습니다. 민감한 정보 검색을 다른 권한 수준으로 제한할 수도 있습니다.13  
* **지식 확장 및 도메인 적응**: RAG는 LLM이 초기 학습 데이터를 넘어 외부 지식 소스를 활용하여 지식 범위를 확장하고, 특정 도메인(예: 과학 연구, 의료 진단, 법률 분석)에 적응할 수 있도록 합니다.14  
* **설명 가능한 AI 기여**: 생성 과정에서 사용된 외부 소스를 투명하게 보여줌으로써 LLM 출력의 해석 가능성을 높여 AI 시스템에 대한 신뢰와 이해를 증진시킵니다.14

**2025년 RAG의 발전 동향 및 과제**

2025년에는 RAG가 LLM의 한계를 해결하고 새로운 가능성을 열어주는 변혁적인 힘이 될 것으로 예상됩니다.14 특히, 멀티모달 검색 시스템과의 통합을 통해 이미지, 비디오, 구조화된 데이터 등 다양한 유형의 데이터를 활용하여 더 풍부한 언어 생성을 가능하게 할 잠재력이 있습니다.14

그러나 RAG는 여러 과제에 직면해 있습니다. 방대하고 다양한 데이터 소스에서 관련 정보를 신속하게 찾는 효율적인 검색 시스템 개발이 여전히 도전 과제이며, 특히 실시간 애플리케이션의 경우 더욱 그렇습니다.14 검색된 정보의 품질과 신뢰성을 보장하는 것이 중요하며, 품질이 낮은 데이터는 LLM 출력의 오도 가능성을 높일 수 있습니다. 맥락 통합 및 일관성 유지 또한 복잡한 문제입니다.14 개인 정보 보호, 편향, 유해 콘텐츠 확산 가능성 등 윤리적 고려 사항도 RAG 시스템 설계에 필수적입니다.14

RAG는 LLM의 '환각(Hallucination)' 문제를 해결하고 '실시간성'을 확보하는 핵심 솔루션으로 자리매김하고 있습니다. LLM은 학습 데이터에 없는 정보를 요청받거나, 복잡한 추론 과정에서 '환각'이라고 불리는 사실과 다른 내용을 그럴듯하게 지어내는 경향이 있습니다. 또한, 학습 데이터가 특정 시점까지의 정보만을 포함하므로 최신 정보에 대한 응답이 어렵습니다. RAG의 핵심 이점은 "권위 있는 외부 지식 기반 참조"와 "최신 정보 제공"에 있습니다.13 RAG는 "사실 확인 및 검증"을 통해 LLM 생성 출력의 '사실적 정확성과 신뢰성'을 향상시키고, "잘못된 정보나 부정확성의 확산 위험을 완화"한다고 강조됩니다.14 이는 LLM이 자체적으로 생성한 정보가 아닌, 검증된 외부 소스에서 정보를 가져오도록 함으로써 환각을 줄이는 메커니즘입니다. 또한, RAG는 "개발자가 최신 연구, 통계 또는 뉴스를 생성 모델에 제공할 수 있도록 한다"고 언급되며, "LLM을 라이브 소셜 미디어 피드, 뉴스 사이트 또는 기타 자주 업데이트되는 정보 소스에 직접 연결"하여 최신 정보를 제공할 수 있음을 보여줍니다.13

LLM의 환각은 학습 데이터의 한계나 모델의 내재적 추론 오류에서 비롯됩니다. RAG는 이러한 LLM의 '내부 지식'에만 의존하는 한계를 외부의 '검증된 지식'으로 보완합니다. 이는 마치 인간이 모르는 질문에 대해 인터넷 검색을 통해 정보를 얻어 답변하는 것과 유사합니다. 이 과정에서 정보의 출처가 명확해지므로, 모델의 답변에 대한 신뢰도가 자연스럽게 높아집니다. 또한, LLM의 학습 데이터는 고정되어 있지만, RAG는 실시간으로 업데이트되는 외부 데이터베이스와 연동될 수 있어, 모델이 항상 최신 정보를 기반으로 응답할 수 있게 됩니다. RAG는 LLM이 가진 고질적인 '환각' 문제와 '정보 최신성' 문제를 동시에 해결하는 강력한 기술입니다. 이는 LLM이 단순히 텍스트를 생성하는 도구를 넘어, 신뢰할 수 있는 '지식 에이전트'로 기능할 수 있는 기반을 제공합니다. 특히 기업용 애플리케이션이나 법률, 의료와 같이 정확성과 최신성이 절대적으로 요구되는 분야에서 RAG는 LLM 도입의 필수적인 요소로 부상하고 있으며, 2025년에도 그 중요성이 더욱 커질 것으로 예상됩니다.

### **2.4 자기 수정 (Self-Correction) 프롬프팅**

**정의 및 필요성**

자기 수정 프롬프팅은 LLM의 응답이 정확하고 신뢰할 수 있도록 모델이 자신의 출력을 비판하고 개선하도록 유도하는 강력한 접근 방식입니다.15 LLM은 때때로 올바른 답변과 잘못된 답변을 동일한 수준의 확신을 가지고 제공할 수 있어, 어떤 것을 신뢰해야 할지 판단하기 어렵다는 문제가 있습니다.15 자기 수정 기법은 이러한 문제를 해결하여 모델이 스스로 오류를 감지하고 수정하도록 돕습니다.

**주요 기법 및 작동 원리**

* **Self-Calibration**: 이 기법은 LLM이 응답을 생성한 후 자신의 출력을 평가하도록 프롬프팅하여, 실수를 발견하고 오탐 및 미탐의 가능성을 줄이는 데 도움을 줍니다.15  
* **Self-Refine**: 인간이 초안을 작성하고 검토 및 개선하는 과정과 유사하게, LLM이 초기 출력을 생성한 다음 단계별로 반복적으로 개선하여 정확성과 품질을 향상시킵니다.15  
* **Reversing Chain-of-Thought (RCoT)**: CoT 프롬프팅의 개념을 역으로 활용하여 환각이나 잘못된 가정을 감지하고 수정하는 데 도움을 줍니다. 모델이 문제를 해결한 후, 초기 솔루션을 기반으로 새로운 문제를 생성하도록 요청하고, 원본 문제와 새로 생성된 문제를 비교하여 불일치를 발견합니다.15  
* **Self-Verification**: CoT 프롬프팅이 추론에 효과적이지만 오류 수정 메커니즘이 부족하다는 점을 보완합니다. CoT를 사용하여 여러 후보 솔루션을 생성한 다음, 원본 질문의 일부를 마스킹하여 각 솔루션을 평가합니다. LLM은 질문의 나머지 부분과 생성된 솔루션을 기반으로 누락된 정보를 예측해야 합니다.15  
* **Chain-of-Verification (CoVe)**: CoT와 유사하지만, 중간 단계를 생성하는 대신 모델이 초기 응답을 평가하기 위한 검증 질문을 생성하도록 합니다. 모델은 이 질문에 답변하여 최종 출력을 다듬습니다.15  
* **Cumulative Reasoning (CR)**: 문제 해결을 여러 단계로 나누고, 각 단계를 LLM이 평가하여 수락 또는 거부할지 결정합니다. 최종 답변에 도달하면 중단하고, 그렇지 않으면 해결책에 도달할 때까지 계속 개선합니다.15  
* **Chain of Self-Correction (CoSC)**: 2025년 상반기 연구에서 제시된 새로운 메커니즘으로, LLM에 자체 수정 능력을 내재화하도록 설계되었습니다. LLM이 문제를 해결하기 위한 프로그램을 생성하고, 이를 실행하여 출력을 얻은 후 검증하는 일련의 자체 수정 단계를 통해 작동합니다. 이 반복적인 과정은 LLM이 추론 단계를 개선하고 수학적 추론의 정확성을 향상시키도록 합니다.16 CoSC-Code-34B 모델은 MATH 데이터셋(가장 어려운 수학적 추론 데이터셋)에서 ChatGPT, GPT-4, 멀티모달 LLM을 능가하는 성능을 보였습니다.16

자기 수정 기법은 LLM의 '신뢰성'과 '정확성'을 근본적으로 개선하며, 특히 '수학적 추론'과 같은 논리적 과제에서 인간의 '느린 사고(slow thinking)' 과정을 모방합니다. LLM의 오류는 종종 '빠른 사고(fast thinking)'와 유사한 즉각적인 패턴 매칭에서 발생합니다. 자기 수정 기법은 이러한 즉각적인 응답 대신, '느린 사고'처럼 단계별로 문제를 분석하고, 중간 결과를 검증하며, 필요에 따라 수정하는 과정을 모델에 주입합니다. 특히 CoSC는 모델이 '프로그램 실행'이라는 외부 도구를 활용하여 자신의 추론을 검증하도록 함으로써, 단순히 텍스트 내에서만 추론하는 한계를 넘어섭니다.16 이는 모델이 자신의 '생각'을 '행동'으로 옮기고 그 결과를 '관찰'하여 '피드백'으로 삼는 고차원적인 학습 루프를 형성하는 것입니다. 이 과정을 통해 모델은 자신의 오류를 능동적으로 찾아내고 수정함으로써, 논리적 일관성과 사실적 정확성을 획기적으로 향상시킬 수 있습니다.

자기 수정 프롬프팅은 LLM의 '지능'을 단순한 언어 생성기를 넘어 '문제 해결자'이자 '자기 개선 학습자'로 진화시키는 중요한 단계입니다. 특히 수학이나 코딩과 같이 명확한 정답과 논리적 검증이 가능한 분야에서 그 효과가 두드러지며, 이는 LLM이 더욱 복잡하고 비판적인 사고를 요구하는 실제 세계 문제에 적용될 수 있음을 시사합니다. 이러한 기법들은 LLM이 인간의 인지 과정을 모방하여 더욱 신뢰할 수 있는 AI 시스템으로 발전하는 데 핵심적인 역할을 할 것입니다.

### **2.5 다중 전문가 (Multi-expert) 프롬프팅**

**정의 및 메커니즘**

다중 전문가 프롬프팅(Multi-expert Prompting)은 기존의 ExpertPrompting을 개선한 새로운 방법으로, LLM이 여러 전문가를 시뮬레이션하고, 이들의 응답을 통합한 후, 개별 및 통합 응답 중에서 최상의 것을 선택하여 출력을 향상시키는 기법입니다.19 이 과정은 단일 CoT(Chain of Thoughts) 내에서 7개의 세심하게 설계된 하위 작업을 활용하여 수행됩니다. 이 하위 작업들은 의사 결정 프레임워크인 명목 집단 기법(Nominal Group Technique, NGT)에서 파생되었습니다.19

LLM은 입력 지시에 따라 여러 전문가 정체성(expert identities)을 제로샷 프롬프팅 스타일로 생성하며, 각 전문가는 독립적으로 지시에 응답합니다.20 이후 모델은 이 전문가들의 응답을 결합하고 최상의 응답을 선택합니다.20 메타 프롬프팅(Meta Prompting)은 LLM을 '지휘자(conductor)'로 사용하여 특정 분야의 전문가인 여러 독립적인 LLM을 관리하는 방식과 유사합니다.22 Brokered Multi-Expert Reflection은 기본 LLM의 추론 경로에 대한 피드백을 제공하기 위해 반성(reflection) 계층 내에서 여러 전문가 LLM을 중개하고 통합하여 LLM의 추론 능력을 향상시킵니다.23

**장점 및 효과**

다중 전문가 프롬프팅은 기존 ExpertPrompting 및 유사한 기준선 대비 진실성(truthfulness), 사실성(factuality), 정보성(informativeness), 유용성(usefulness)을 크게 향상시키고, 독성(toxicity) 및 유해성(hurtfulness)을 감소시킵니다.19 ChatGPT와 함께 사용 시 최상의 기준선보다 8.69% 높은 최첨단 진실성을 달성했습니다.19 이 방법은 효율적이고, 설명 가능하며, 다양한 시나리오에 대한 높은 적응성을 가지며, 수동적인 프롬프트 구성이 필요 없습니다.19 또한, 단일 전문가가 가질 수 있는 편향을 해결하고, 개방형 지시에 대한 다양한 관점을 고려하는 데 필요한 깊이를 제공합니다.20 환각 및 불일치 문제를 효과적으로 해결하며, 특히 도메인별 작업에서 정확하고 신뢰할 수 있는 결론을 도출하는 데 큰 잠재력을 보여줍니다.23

다중 전문가 프롬프팅은 LLM의 '편향'을 줄이고 '다각적인 관점'을 통합하여 복잡한 문제 해결 능력을 향상시키는 집단 지성(Collective Intelligence)의 AI 버전입니다. 단일 LLM은 학습 데이터의 편향을 반영하거나, 특정 관점에만 치우쳐 답변을 생성할 수 있습니다. 이는 특히 윤리적, 사회적, 또는 복잡한 다면적 문제에서 한계로 작용합니다. ExpertPrompting은 "단순한 답변을 제공하고 비윤리적이라고 라벨링함으로써 편향과 다른 관점에 대한 무시하는 태도를 도입"할 수 있다는 지적이 있습니다.20 이에 대한 해결책으로 Multi-expert Prompting은 "여러 전문가를 시뮬레이션하고, 그들의 응답을 통합하며, 개별 및 통합 응답 중에서 최상의 것을 선택"한다고 설명됩니다.19 이 기법은 명목 집단 기법(Nominal Group Technique)에서 파생된 7가지 하위 작업을 통해 단일 CoT 내에서 진행됩니다.20 Brokered Multi-Expert Reflection 또한 "여러 전문가 LLM을 통합"하여 환각 및 불일치 문제를 해결하고 "도메인별 작업에서 상당한 잠재력"을 보인다고 언급됩니다.23

인간 사회에서 복잡한 문제를 해결할 때 다양한 분야의 전문가들이 모여 의견을 교환하고 합의를 도출하는 과정이 효과적입니다. 다중 전문가 프롬프팅은 이러한 '집단 지성'의 원리를 LLM에 적용한 것입니다. 단일 LLM이 특정 역할을 맡아 답변을 생성하는 것이 아니라, 여러 '가상 전문가'들이 각자의 관점(예: 윤리학자, 경제학자, 환경론자)에서 문제를 분석하고 답변을 내놓습니다. 이후 이 다양한 답변들을 통합하고 최적의 답변을 선택하는 과정을 통해, 모델은 특정 편향에 갇히지 않고 더 균형 잡히고 포괄적인 시각을 제공할 수 있게 됩니다. 이는 마치 여러 전문가가 브레인스토밍을 통해 아이디어를 생성하고, 토론을 통해 검증하며, 최종적으로 합의된 결론을 도출하는 과정과 유사합니다. 다중 전문가 프롬프팅은 LLM의 '지식' 활용 방식을 혁신적으로 확장합니다. 이는 모델이 단순히 정보를 나열하는 것을 넘어, '다각적인 분석'과 '종합적인 판단'을 수행하도록 돕습니다. 특히, 정답이 명확하지 않거나 다양한 이해관계가 얽힌 복잡한 사회적, 윤리적 문제에서 LLM의 답변 품질과 신뢰성을 크게 향상시킬 수 있습니다. 이 기법은 LLM이 더욱 '사려 깊고' '균형 잡힌' AI 시스템으로 발전하는 데 중요한 방향을 제시합니다.

다음 표는 위에서 설명한 주요 LLM 프롬프팅 기법들을 비교하여 제시합니다.

**표 1: 주요 LLM 프롬프팅 기법 비교**

| 기법 | 정의 | 메커니즘 요약 | 장점 | 단점/한계 | 주요 활용 사례 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **제로샷 프롬프팅** | 예시 없이 지시만으로 LLM이 작업을 수행하도록 요청 | 사전 학습된 지식에 전적으로 의존하여 응답 생성 | 빠른 배포, 비용 효율적, 레이블링 데이터 불필요 | 문구에 민감, 복잡한 작업에 부적합 | 번역, 요약, 콘텐츠 중재, 스팸 감지, 감성 분석 |
| **퓨샷 프롬프팅** | 프롬프트 내에 2\~5개의 예시를 포함하여 LLM이 학습하도록 유도 | 예시를 통해 패턴을 식별하고 새로운 입력에 적용 (인컨텍스트 학습) | 복잡한 작업 정확도 향상, 빠른 적응 및 배포, 자원 효율성 | 긴 프롬프트, 높은 계산 비용, 컨텍스트 창 제한, 과적합 위험 | 텍스트 분류, 감성 분석, 정보 추출, 질문 답변, 콘텐츠 생성 |
| **Chain-of-Thought (CoT) 프롬프팅** | LLM이 단계별 추론 과정을 거치도록 안내하여 복잡한 문제 해결 | "단계별로 생각하라" 지시를 통해 중간 추론 단계 생성 | 복잡한 추론 능력 향상, 투명성 증대, 논리적 오류 감소 | 간단한 작업에는 비효율적, 긴 출력 생성 가능성 | 수학적 추론, 상식 추론, 복잡한 문제 해결, 법률 분석 |
| **Retrieval-Augmented Generation (RAG) 프롬프팅** | LLM이 외부 지식 기반을 참조하여 최신 정보로 응답 생성 | 사용자 쿼리 기반으로 외부 데이터 검색 후 LLM에 맥락으로 제공 | 최신 정보 제공, 환각 감소, 사용자 신뢰도 향상, 비용 효율성 | 효율적인 검색 시스템 구축 난이도, 정보 품질 관리 필요 | 고객 지원 챗봇, 규제 준수, 지식 관리, 공급망 최적화 |
| **자기 수정 (Self-Correction) 프롬프팅** | LLM이 자신의 출력을 비판하고 개선하도록 유도 | 모델이 자체적으로 오류를 감지하고 반복적으로 수정 | 응답의 정확성 및 신뢰성 향상, 논리적 일관성 증대 | 복잡한 구현, 추가적인 계산 필요 | 수학적 추론, 코드 생성, 사실 확인, 비판적 분석 |
| **다중 전문가 (Multi-expert) 프롬프팅** | LLM이 여러 전문가를 시뮬레이션하고 응답을 통합하여 최적의 결과 선택 | 여러 가상 전문가의 관점 통합 및 최상의 응답 집계 | 편향 감소, 다각적 관점 통합, 진실성/사실성/유용성 향상 | 전문가 역할 정의의 복잡성, 통합 과정의 미묘함 | 복잡한 사회/윤리적 문제, 전략 분석, 창의적 콘텐츠 생성 |

## **3\. LLM 프롬프트 최적화 및 평가 전략**

LLM 프롬프트의 성능을 극대화하기 위해서는 지속적인 최적화와 체계적인 평가가 필수적입니다.

### **3.1 프롬프트 최적화 기법**

프롬프트 최적화는 LLM의 출력을 개선하기 위한 핵심적인 과정입니다. 과거에는 프롬프트 엔지니어링이 "임시적(ad-hoc)이고 시행착오적 프롬프트 반복" 방식에 의존했습니다.3 그러나 이제는 LLM을 사용하여 프롬프트를 생성하고 개선하는 자동화된 방법론이 부상하고 있습니다.

\*\*자동화된 프롬프트 엔지니어링 (APE)\*\*은 LLM을 사용하여 프롬프트를 생성하고 개선하는 메타 프롬프팅(Meta Prompting) 방법론의 일종입니다.22 이 방법은 초기 입력-출력 쌍을 기반으로 여러 지시 후보를 생성하고, 이 후보들의 효과를 점수화하며, 반복적인 과정을 통해 최적의 성능을 달성하도록 지시를 개선합니다.22 APE는 인간이 설계한 프롬프트보다 일관되게 우수한 성능을 보였으며, 다양한 시나리오(제로샷, CoT 등)에 적응 가능하고, 작업에 구애받지 않는(task-agnostic) 특성을 가집니다.22

\*\*로컬 프롬프트 최적화 (LPO)\*\*는 자동화된 프롬프트 엔지니어링 방법과 통합되어, 프롬프트 내의 특정 '최적화 토큰'에 초점을 맞춰 LLM이 해당 토큰에만 집중하도록 유도합니다.24 이 기법은 수학적 추론 벤치마크(GSM8k, MultiArith)에서 뛰어난 성능 향상을 보였으며, 전역 최적화 방법보다 더 빠르게 최적 프롬프트로 수렴합니다.24

프롬프트 요구사항의 **과다 지정 문제**는 LLM 성능 저하의 주요 원인으로 지적됩니다. LLM은 너무 많은 요구사항이 포함된 프롬프트에 어려움을 겪으며, 이는 성능 저하로 이어질 수 있습니다.3 19개의 요구사항을 함께 지정했을 때 LLM의 평균 정확도가 크게 떨어지는 것이 관찰되었습니다.3 이러한 문제를 해결하기 위한 방안으로, \*\*의도적인 불완전 지정(intentional underspecification)\*\*은 모델이 기본적으로 따르는 요구사항을 제외하고, 선택된 핵심 요구사항에만 집중하도록 하는 전략이 될 수 있습니다.3 이를 위해서는 요구사항의 사전 발견, 신뢰할 수 있는 평가자 구축, 지속적인 평가 및 모니터링을 포함하는 광범위한 프로세스가 필요합니다.3

2025년 상반기에는 다음과 같은 최신 프롬프트 최적화 기법들이 연구되었습니다.

* **Recursive Self-Improvement Prompting (RSIP) / Alignment via Refinement (AvR)**: 이 접근 방식은 모델이 자신의 출력을 반복적으로 비판하고 개선하도록 합니다.25 AvR은 CoT를 통해 LLM의 재귀적 사고 능력을 향상시키며, 비판 및 개선 작업을 통합하고 차등 학습 기술로 최적화합니다.27 적은 양의 합성 데이터(3k 샘플)로도 LLaMA-3-8B-Instruct 모델의 성능을 AlpacaEval 2.0에서 20% 이상 향상시키는 효율성을 보였습니다.27  
* **Multi-Objective Directional Prompting (MODP)**: LLM의 내재적 행동을 추가 목표로 고려하고, 지표 기반의 프롬프트 엔지니어링을 통해 견고하고 고정밀 프롬프트를 개발하는 프레임워크입니다.26 정확성, 독성 감소, 특정 출력 형식 준수 등 여러 목표의 균형을 맞추는 데 중점을 둡니다.28  
* **Mixture of Formats (MOF)**: LLM이 프롬프트 형식의 비의미적 변화에 민감한 '프롬프트 취약성(prompt brittleness)' 문제를 해결합니다.26 퓨샷 예시의 스타일을 다양화하여 모델이 특정 스타일과 대상 변수를 연관 짓는 것을 방지하고, 전반적인 성능을 향상시킵니다.30

프롬프트 최적화는 '인간의 시행착오'에서 'LLM의 자율적 개선'으로 진화하고 있으며, 이는 LLM 애플리케이션 개발의 효율성을 획기적으로 높일 것으로 기대됩니다. 과거에는 프롬프트 엔지니어가 수많은 프롬프트 변형을 수동으로 작성하고 테스트하며 최적의 것을 찾아야 했습니다. 이는 시간과 비용이 많이 드는 비효율적인 과정이었습니다. 그러나 APE, LPO, RSIP/AvR과 같은 자동화된 기법들은 LLM 자체의 지능을 활용하여 프롬프트 생성, 평가, 개선 과정을 자동화합니다.22 이는 LLM이 단순히 최종 결과물을 생성하는 도구를 넘어, '자신을 개선하는 도구'로 진화하고 있음을 의미합니다. 이러한 자율적인 최적화는 인간의 개입을 최소화하면서도 프롬프트의 품질과 효율성을 극대화할 수 있습니다. 프롬프트 최적화의 자동화는 LLM 기반 애플리케이션의 개발 주기를 단축하고, 더 적은 자원으로 더 높은 성능을 달성할 수 있게 합니다. 이는 프롬프트 엔지니어링의 '장인 정신'을 '공학적 프로세스'로 전환하는 중요한 변화입니다. 개발자들은 이제 프롬프트의 세부 문구에 대한 고민보다는, 최적화 알고리즘의 설계와 평가 지표 설정에 더 집중할 수 있게 됩니다. 궁극적으로 이는 LLM 기술의 대중화와 산업 적용을 가속화하는 핵심 동력이 될 것입니다.

### **3.2 LLM 프롬프트 평가 방법론 및 지표**

LLM 프롬프트의 효과를 객관적으로 측정하고 개선하기 위해서는 적절한 평가 방법론과 지표가 필수적입니다. LLM 벤치마크는 특정 LLM 모델의 코딩 능력, 대화 관련성, 추론 문제 해결 능력 등 전반적인 역량을 평가하는 데 도움이 됩니다.31 LLM 평가 지표는 정확성, 관련성, 환각 등 사용자가 중요하게 생각하는 기준에 따라 LLM 시스템의 출력을 평가합니다.32

**기존 지표의 한계 및 LLM-as-a-judge**

BLEU/ROUGE와 같은 전통적인 평가 지표는 LLM 출력의 '의미론적 뉘앙스'를 포착하지 못하는 한계가 있습니다.32 대신,

**LLM-as-a-judge**는 LLM을 평가자로 사용하여 자연어 루브릭(rubrics)으로 출력을 평가하는 가장 신뢰할 수 있는 방법으로 간주됩니다.32 이 방법은 G-Eval과 같은 다양한 기술을 필요로 하며, 시스템(RAG, 에이전트, 챗봇) 및 사용 사례(Text-SQL, 글쓰기 도우미)에 따라 지표 선택이 달라집니다.32 좋은 평가 지표는 정량적(점수 산출), 신뢰성(일관성), 정확성(인간의 기대치와 일치)을 갖춰야 합니다.32

**RAG 특정 지표**

* **응답 관련성 (Answer Relevancy)**: LLM 출력이 주어진 입력에 대해 유익하고 간결하게 응답하는지 평가합니다. 검색 맥락을 고려하여 관련 문장의 비율을 계산합니다.32  
* **맥락 정밀도 (Contextual Precision)**: RAG 파이프라인의 검색기(retriever) 품질을 평가합니다. 검색 맥락에서 관련 노드가 관련 없는 노드보다 더 높은 순위로 매겨지는지 확인합니다. LLM이 검색 맥락의 초반에 나타나는 정보에 더 많은 가중치를 부여하므로 중요합니다.32

**기타 평가 지표**

* **Perplexity**: 모델이 텍스트 샘플을 얼마나 잘 예측하는지 측정하며, 점수가 낮을수록 성능이 좋습니다.33  
* **BLEU Score**: 주로 기계 번역에 사용되며, n-그램 중첩을 통해 모델 출력과 참조 텍스트를 비교합니다.33  
* **ROUGE**: 요약 평가에 적합하며, 모델이 생성한 콘텐츠가 참조 요약과 얼마나 중첩되는지 측정합니다.33  
* **F1 Score**: 분류 및 질문 답변 작업에 사용되며, 정밀도(precision)와 재현율(recall)의 균형을 맞춥니다.33  
* **METEOR**: 정확한 일치뿐만 아니라 동의어 및 의역도 고려하여 인간의 판단과 더 잘 일치하도록 합니다.33  
* **BERTScore**: BERT와 같은 모델의 컨텍스트 임베딩 유사성을 비교하여 의미에 더 중점을 둡니다.33  
* **Levenshtein distance**: 두 문자열을 변경하는 데 필요한 단일 문자 편집(삽입, 삭제, 대체)의 최소 수를 측정합니다.33  
* **작업별 지표**: 대화 시스템의 참여 수준, 작업 완료율, 코드 생성의 컴파일 성공 여부 및 테스트 통과율 등 특정 작업에 특화된 지표도 사용됩니다.33  
* **효율성 지표**: 모델이 커짐에 따라 속도, 메모리 사용량, 에너지 소비량 측정이 중요해집니다.33

**평가 프레임워크 및 도구**

SuperAnnotate, Amazon Bedrock, Nvidia Nemo, Azure AI Studio, Prompt Flow 등 다양한 도구들이 LLM 평가를 위한 내장 지표와 사용자 정의 가능한 평가 흐름을 제공합니다.33

LLM 평가 패러다임은 '표면적 유사성'에서 '의미론적 정확성 및 인간적 판단 일치'로 진화하고 있으며, 이는 LLM의 실용적 가치 측정에 필수적입니다. 전통적인 NLP 모델 평가에서는 BLEU, ROUGE와 같은 n-그램 기반의 지표가 널리 사용되었지만, LLM 출력의 '의미론적 뉘앙스'를 포착하지 못하는 한계가 있습니다.32 대신, "LLM-as-a-judge" 방식이 "자연어 루브릭을 사용하여 LLM을 평가자로 사용하는 가장 신뢰할 수 있는 방법"으로 제시됩니다.32 좋은 LLM 평가 지표의 비밀은 인간의 기대치와 최대한 일치하도록 만드는 것입니다.32 또한, '배치 프롬프팅(Batched Prompting)'과 '프롬프트 압축(Prompt Compression)'이 효율성을 높이면서도 품질 저하를 완화하는 연구 동향을 보여주며, 'PrExMe'와 'PromptOptMe'와 같은 연구는 다양한 프롬프트 템플릿이 LLM 기반 평가 지표의 성능에 미치는 영향을 탐구하고 있습니다.34

LLM은 단순히 단어 시퀀스를 생성하는 것을 넘어, 복잡한 의미를 이해하고 추론하며, 창의적인 텍스트를 생성할 수 있습니다. 이러한 능력은 전통적인 n-그램 중첩 기반 지표로는 제대로 평가하기 어렵습니다. 예를 들어, 동일한 의미를 가지지만 표현 방식이 완전히 다른 두 문장은 BLEU 점수가 낮을 수 있지만, 실제로는 둘 다 올바른 답변일 수 있습니다. 'LLM-as-a-judge'는 이러한 의미론적 이해의 격차를 메우기 위해, 또 다른 LLM이 인간처럼 텍스트의 의미, 논리, 맥락적 적합성을 평가하도록 합니다. 이는 평가 자체가 '지능적인 판단'을 요구하는 작업이 되었음을 의미합니다. 또한, RAG 시스템의 경우, 답변의 정확성뿐만 아니라 검색된 맥락의 관련성(Contextual Precision)까지 평가하는 등 시스템의 특정 아키텍처에 맞는 정교한 지표가 필요해졌습니다.32 LLM 평가의 진화는 LLM이 단순한 규칙 기반 시스템이 아닌, 복잡한 인지 능력을 가진 '준-지능' 시스템으로 인식되고 있음을 반영합니다. 이제 평가는 '정답과의 일치'를 넘어 '의미론적 타당성', '인간적 만족도', '시스템의 신뢰성' 등 다차원적인 관점에서 이루어져야 합니다. 이는 LLM 애플리케이션의 품질 관리와 지속적인 개선을 위해 필수적이며, LLM이 실제 비즈니스 및 사회 문제 해결에 더 깊이 통합될 수 있도록 하는 중요한 기반을 제공합니다.

다음 표는 LLM 프롬프트 평가에 사용되는 주요 지표와 그 활용법을 요약합니다.

**표 3: LLM 프롬프트 평가 지표 및 활용**

| 지표 유형 | 측정 대상 | 활용 시점/적합성 | 장점 | 한계 |
| :---- | :---- | :---- | :---- | :---- |
| **Perplexity** | 모델이 텍스트 샘플을 얼마나 잘 예측하는지 | 언어 모델의 전반적인 예측 능력 평가 | 모델의 유창성 및 예측 정확도 정량화 | 텍스트의 품질, 일관성, 의미론적 뉘앙스 미반영 |
| **BLEU Score** | 모델 출력과 참조 텍스트 간의 n-그램 중첩 | 기계 번역, 텍스트 생성 | 객관적이고 자동화된 평가, 광범위하게 사용 | 창의적이거나 다양한 텍스트 출력 평가에 부적합, 의미론적 유사성 미반영 |
| **ROUGE** | 모델 생성 콘텐츠와 참조 요약 간의 중첩 (n-그램, 시퀀스, 단어 쌍) | 텍스트 요약, 요약 품질 평가 | 요약의 내용적 일치도 평가에 효과적 | 문맥적 이해 부족, 다양한 표현 방식의 요약 평가에 제한적 |
| **F1 Score** | 정밀도(Precision)와 재현율(Recall)의 균형 | 분류 및 질문 답변 작업 | 모델 응답의 관련성(정밀도)과 완전성(재현율) 동시 평가 | 이진 분류 외 다중 클래스/복잡한 시나리오에 적용 어려움 |
| **METEOR** | 정확한 일치, 동의어, 의역 포함 | 기계 번역, 텍스트 생성 | 인간의 판단과 더 잘 일치하도록 설계, 의미론적 유사성 일부 반영 | 계산 복잡성, 참조 번역의 품질에 민감 |
| **BERTScore** | 컨텍스트 임베딩 유사성 비교 | 텍스트 생성, 기계 번역 | 의미에 더 중점, 단어 일치보다 문맥적 유사성 평가 | 계산 자원 소모, 특정 BERT 모델에 의존적 |
| **Levenshtein distance** | 두 문자열을 변경하는 데 필요한 최소 편집 수 | 텍스트 유사성, 오탈자 교정, OCR 후처리 | 간단하고 직관적, 문자 단위의 정확성 평가 | 의미론적 유사성 미고려, 긴 텍스트에 대한 유용성 제한 |
| **응답 관련성 (RAG)** | LLM 출력이 입력에 대해 유익하고 간결한지 | RAG 시스템의 생성기 품질 평가 | 답변의 핵심 내용이 질문과 얼마나 관련 있는지 측정 | 검색 맥락의 품질에 따라 평가 결과가 달라질 수 있음 |
| **맥락 정밀도 (RAG)** | RAG 파이프라인의 검색기 품질, 관련 노드 순위 | RAG 시스템의 검색 단계 품질 평가 | LLM이 참조하는 정보의 정확성과 관련성 보장 | 검색된 정보의 양과 질에 따라 평가 결과가 달라질 수 있음 |
| **LLM-as-a-judge (G-Eval 등)** | 자연어 루브릭을 사용한 LLM 출력 평가 | 모든 LLM 시스템 및 사용 사례, 특히 의미론적 평가 | 인간의 판단과 높은 일치도, 의미론적 뉘앙스 포착 | 평가 LLM의 편향 가능성, 일관성 문제 발생 가능성 |

## **4\. 2025년 상반기 LLM 프롬프팅의 최신 동향 및 미래 전망**

2025년 상반기는 LLM 프롬프팅 분야에서 혁신적인 발전이 이루어진 시기였으며, 이는 LLM의 기능과 적용 범위를 더욱 확장하고 있습니다.

**새로운 모델 및 기능의 발전**

OpenAI의 "o" 시리즈(o1, o3, o4-mini), Google의 Gemini 2.0/2.5, Anthropic의 Claude 3.7과 같은 모델들은 추론, 코딩, 수학 및 복잡한 문제 해결 능력의 한계를 확장하고 있습니다.26 일부 모델은 "사고 과정"을 보여주려고 시도하기도 합니다.26 또한, Microsoft의 Phi-3 시리즈와 같이 작지만 강력하고 효율적인 모델들이 등장하여, 더 큰 모델과 유사한 성능을 제공하면서도 비용 효율성을 높이고 있습니다.26

**주요 신규 프롬프팅 패러다임**

* **Mixture of Formats (MOF)**: LLM이 프롬프트 형식의 비의미적 변화에 민감한 '프롬프트 취약성(prompt brittleness)'을 해결하기 위해, 퓨샷 예시 내에서 다양한 스타일을 활용하는 기법입니다.26 이는 모델이 특정 스타일과 대상 변수를 연관 짓는 것을 방지하여 전반적인 성능을 향상시킵니다.30  
* **Multi-Objective Directional Prompting (MODP)**: LLM의 내재적 행동을 추가 목표로 고려하고, 지표 기반의 프롬프트 엔지니어링을 통해 견고하고 고정밀 프롬프트를 개발하는 프레임워크입니다.26 정확성, 독성 감소, 특정 출력 형식 준수 등 여러 목표의 균형을 맞추는 데 중점을 둡니다.28  
* **Recursive Self-Improvement Prompting (RSIP) / Alignment via Refinement (AvR)**: 모델이 자신의 출력을 반복적으로 비판하고 개선하도록 하는 접근 방식입니다.25 AvR은 CoT를 통해 LLM의 재귀적 사고 능력을 향상시키며, 적은 양의 합성 데이터로도 LLaMA-3-8B-Instruct 모델의 성능을 크게 향상시켰습니다.27  
* **Context-Aware Decomposition**: 테이블 질의 응답(TableQA)과 같은 도메인별 AI 애플리케이션을 위한 동적 컨텍스트 인식 프롬프트 추천 시스템입니다.35 SQL 기반 분해 모델(TABSD)은 LLM이 대규모 자유 형식 테이블을 처리하는 능력을 향상시키며 36, 각 토큰에 개별 프롬프트를 생성하는 분해 프롬프팅(Decomposed Prompting)도 연구되고 있습니다.37  
* **Calibrated Confidence Prompting**: LLM이 자신의 예측에 대해 과도하게 확신하는 경향을 해결하기 위해, 프롬프팅을 통해 LLM의 확신 점수를 조절하는 기법입니다.25 SteeringConf 프레임워크는 확신 조절, 집계, 선택의 세 가지 구성 요소를 포함합니다.38 그러나 LLM이 동적인 다중 턴 작업에서 자신의 확신을 정확하게 조정하는 능력은 여전히 부족하다는 연구 결과도 있습니다.39

**에이전트 AI 및 다중 모달 프롬프팅과의 연계**

LLM 기반 에이전트(Agentic AI)는 LLM을 다단계 흐름에 통합하여 상태를 유지하고 맥락과 일관성을 제공함으로써 LLM의 능력을 한 단계 더 발전시킵니다.40 Google의 Project Astra나 OpenAI의 Operator와 같은 에이전트 AI는 스마트한 모델과 스마트한 프롬프팅이 모두 필요합니다.26 적응형 및 다중 모달(Multimodal) 프롬프트는 대화에 따라 변화하고, 텍스트뿐만 아니라 이미지, 오디오, 비디오와도 작동하는 프롬프트를 의미합니다.26 RAG의 미래 발전 방향에도 멀티모달 통합이 포함됩니다.14

**윤리적 프롬프팅 및 안전 문제**

편향을 줄이고 AI 출력을 더 공정하고 안전하게 만들기 위한 '윤리적 프롬프팅'에 대한 큰 추진이 있습니다.26 LLM의 안전 취약성, 특히 유해한 콘텐츠와 의미론적으로 관련된 양성 프롬프트가 안전 메커니즘을 우회할 수 있는 '자연스러운 분포 변화(natural distribution shifts)'에 대한 연구가 ACL 2025에서 발표되었습니다.41 ActorBreaker와 같은 새로운 공격 방법이 Harmbench에서 최고 성공률을 달성하며, 안전 훈련 데이터의 범위를 확장하는 것의 중요성을 강조합니다.41

**자동화 및 효율성 강조**

수동적인 프롬프트 구성보다는 AI 기반의 프롬프트 설계 자동화가 증가할 것으로 예상됩니다.26 강력하면서도 실행 비용이 저렴한 모델의 중요성이 커지고 있습니다.26

2025년 상반기 LLM 프롬프팅 연구는 '단일 프롬프트 최적화'를 넘어 '시스템적 지능 강화'와 '안전성 확보'라는 복합적인 목표로 확장되고 있습니다. 2024년에서 2025년으로 넘어오면서 LLM의 "추론, 코딩, 수학, 복잡한 문제 해결" 능력이 한계점을 넘어서고 있습니다.26 특히, "Multi-Objective Directional Prompting (MODP)"는 정확성뿐만 아니라 "안전성(safety)"과 같은 여러 목표를 동시에 추적하여 프롬프트를 설계하는 방법을 제시합니다.26 ACL 2025에서 발표된 연구는 LLM의 "안전 취약성"과 "유해한 콘텐츠를 드러내도록 LLM을 점진적으로 유도하는 다중 턴 프롬프트"에 대한 새로운 공격 방법인 "ActorBreaker"를 소개하며, "안전 훈련 데이터의 범위를 확장하는 것의 중요성"을 강조합니다.41 또한, "Agentic AI"의 등장은 LLM이 단순히 텍스트를 생성하는 것을 넘어 "항공편 예약이나 이메일 관리"와 같은 실제 행동을 수행할 수 있게 되면서, 모델과 프롬프팅의 통합적 지능이 중요해지고 있음을 보여줍니다.26

LLM의 역량이 고도화되면서, 단순히 '잘 작동하는' 프롬프트를 만드는 것을 넘어, '안전하게', '다목적으로', '자율적으로' 작동하는 시스템을 구축하는 것이 중요해졌습니다. MODP와 같은 기법은 단일 성능 지표가 아닌, 윤리적 고려사항(예: 독성 감소)을 포함한 다중 목표를 최적화함으로써 LLM의 '책임감 있는 배포'를 가능하게 합니다. ActorBreaker와 같은 공격 연구는 LLM의 안전 메커니즘이 우회될 수 있음을 보여주며, 이는 프롬프트 설계가 단순한 성능 최적화를 넘어 '보안'과 '악용 방지' 측면까지 고려해야 함을 의미합니다. 또한, 에이전트 AI의 발전은 프롬프팅이 이제 단일 쿼리-응답 상호작용을 넘어, 복잡한 다단계 작업 흐름과 외부 도구 사용을 조율하는 '지능형 제어 메커니즘'으로 진화하고 있음을 시사합니다. 2025년 상반기 LLM 프롬프팅 연구는 LLM이 단순한 언어 모델이 아닌, 실제 세계에 영향을 미치는 '자율 시스템'으로 발전하고 있음을 명확히 보여줍니다. 이에 따라 프롬프트 엔지니어링은 '개별 프롬프트 작성 기술'에서 'LLM 기반 시스템의 설계 및 운영 전략'으로 그 범위가 확장되고 있습니다. 이는 LLM의 잠재력을 최대한 활용하면서도, 사회적 책임과 안전성을 동시에 확보해야 하는 복합적인 과제를 안고 있음을 의미하며, 향후 LLM 연구 및 개발의 주요 방향성을 제시합니다.

LLM의 '프롬프트 취약성(Prompt Brittleness)'은 여전히 중요한 문제이며, 'Mixture of Formats (MOF)'와 같은 기법은 이를 완화하여 LLM의 '견고성'을 높이는 데 기여합니다. LLM은 자연어를 이해하고 생성하는 능력이 뛰어나므로, 프롬프트의 미세한 형식적 변화에는 둔감할 것이라는 가정이 있을 수 있습니다. 그러나 "LLM이 프롬프트 형식의 비의미적 변화에 민감하며, 프롬프트 형식의 작은 변화가 상당한 성능 변동으로 이어질 수 있다"는 점이 명확히 지적됩니다.30 이를 "프롬프트 취약성"이라고 부릅니다. "추가 공백 추가, 콜론 두 개를 하나로 바꾸기, 퓨샷 예시의 순서 변경, 퓨샷 예시 선택 변경"과 같은 변화가 성능에 영향을 미칠 수 있다고 언급됩니다.30 이에 대한 해결책으로 "Mixture of Formats (MOF)"가 제안되었는데, 이는 "프롬프트 퓨샷 예시에서 사용되는 스타일을 다양화"함으로써 프롬프트 취약성을 해결하고 "다양한 프롬프트 변형과 다른 데이터셋에서 전반적인 성능을 향상"시킨다고 합니다.30

LLM은 방대한 데이터로 학습되었지만, 여전히 입력의 '표면적 특징'에 민감하게 반응하는 경향이 있습니다. 이는 모델이 단순히 의미를 이해하는 것을 넘어, 학습 과정에서 특정 형식이나 패턴에 암묵적으로 의존하게 되었기 때문일 수 있습니다. 프롬프트 취약성은 LLM 애플리케이션의 '견고성(robustness)'과 '신뢰성'을 저해하는 심각한 문제입니다. 동일한 의도를 가진 프롬프트라도 형식만 다르면 성능이 크게 달라진다면, 실제 환경에서의 예측 가능성과 안정성이 떨어지게 됩니다. MOF는 이러한 문제를 해결하기 위해, 다양한 형식의 예시를 제공하여 모델이 '내용'에 더 집중하고 '형식'에 덜 민감하게 반응하도록 훈련하는 일종의 '데이터 증강' 전략을 프롬프트 레벨에서 적용한 것입니다. 이는 모델이 특정 스타일에 과적합되는 것을 방지하고, 더 일반화된 패턴을 학습하도록 돕습니다. 프롬프트 취약성 문제는 LLM의 '블랙박스'적 특성과 '표면적 패턴 학습'의 한계를 다시 한번 상기시킵니다. MOF와 같은 기법은 이러한 LLM의 내재적 특성을 이해하고, 이를 보완하기 위한 프롬프트 설계의 중요성을 강조합니다. 이는 LLM이 실제 환경에서 다양한 사용자 입력과 마주할 때 일관된 성능을 유지하고, 예상치 못한 형식 변화에도 강건하게 작동하도록 만드는 데 필수적인 연구 방향입니다. 궁극적으로 이는 LLM 기반 시스템의 상용화와 신뢰성 확보에 기여할 것입니다.

다음 표는 2025년 상반기에 부상한 주요 LLM 프롬프팅 패러다임을 요약합니다.

**표 2: 2025년 상반기 최신 프롬프팅 패러다임**

| 패러다임 | 핵심 개념 | 주요 특징 | 잠재적 영향/기여 |
| :---- | :---- | :---- | :---- |
| **Mixture of Formats (MOF)** | 프롬프트 형식의 비의미적 변화에 대한 LLM의 민감성(프롬프트 취약성) 완화 | 퓨샷 예시 내에서 다양한 스타일을 활용하여 모델이 내용에 집중하도록 유도 | LLM의 '견고성' 향상, 다양한 입력 형식에 대한 일관된 성능 유지 |
| **Multi-Objective Directional Prompting (MODP)** | LLM의 내재적 행동을 포함한 다중 목표를 고려한 프롬프트 최적화 | 정확성, 안전성, 출력 형식 등 여러 목표의 균형을 지표 기반으로 최적화 | LLM의 '책임감 있는 배포' 지원, 실제 애플리케이션의 신뢰성 및 유용성 증대 |
| **Recursive Self-Improvement Prompting (RSIP) / Alignment via Refinement (AvR)** | LLM이 자신의 출력을 반복적으로 비판하고 개선하도록 하는 자율적 학습 | CoT를 통한 재귀적 사고 능력 향상, 비판/개선 작업을 통합하여 최적화 | LLM의 '자기 개선' 능력 강화, 복잡한 추론 및 문제 해결 능력 획기적 향상 |
| **Context-Aware Decomposition** | 복잡한 작업을 컨텍스트에 따라 여러 하위 작업으로 분해하여 처리 | SQL 기반 테이블 분해, 토큰별 개별 프롬프트 생성 등 | 도메인별 AI 애플리케이션의 정확성 및 효율성 증대, 복잡한 데이터 처리 능력 강화 |
| **Calibrated Confidence Prompting** | LLM의 예측 확신 점수를 조절하여 과도한 확신 경향 해결 | 확신 조절, 집계, 선택 구성 요소를 통한 LLM의 확신도 보정 | LLM 답변의 '신뢰성' 향상, 잘못된 정보 전달 위험 감소 |

## **결론 및 제언**

2025년 상반기 LLM 프롬프팅 분야는 기본적인 명확성, 구체성, 맥락 제공 원칙을 기반으로, 복잡한 추론(CoT), 외부 지식 통합(RAG), 자체 개선(Self-Correction), 다각적 관점 통합(Multi-expert) 등 고도화된 기법들로 빠르게 발전하고 있습니다. 특히, 프롬프트 최적화는 인간의 수동 작업에서 LLM의 자율적 개선으로 진화하고 있으며, 평가 방법론 또한 의미론적 정확성과 인간적 판단 일치에 중점을 두는 방향으로 나아가고 있습니다. 프롬프트의 과다 지정 및 취약성과 같은 도전 과제에 대한 해결책도 활발히 연구되고 있습니다.

이러한 발전은 LLM의 성능을 극대화하고 실제 세계 문제에 효과적으로 적용하기 위한 중요한 기반을 마련하고 있습니다. LLM이 단순한 언어 생성기를 넘어, 신뢰할 수 있는 지식 에이전트, 문제 해결자, 그리고 자율적으로 개선하는 시스템으로 진화하고 있음을 명확히 보여줍니다.

**실용적 제언**

* **기본 원칙 숙지**: 아무리 최신 기법이라도 명확하고 간결하며 맥락을 포함하는 프롬프트 작성의 기본 원칙을 항상 준수해야 합니다.1  
* **복잡성에 따른 기법 선택**: 단순한 작업에는 제로샷을, 특정 패턴 학습이 필요한 경우 퓨샷을, 다단계 추론에는 CoT를, 최신 정보나 외부 지식이 필요한 경우 RAG를 활용하는 등 작업의 복잡성과 요구사항에 따라 적절한 프롬프팅 기법을 선택해야 합니다.6  
* **신뢰성 확보를 위한 투자**: LLM의 환각 및 편향 문제를 해결하기 위해 자기 수정 및 다중 전문가 프롬프팅과 같은 신뢰성 향상 기법을 적극적으로 도입하고, 이를 위한 평가 지표 및 프레임워크를 구축해야 합니다.15  
* **자동화된 최적화 도구 활용**: 프롬프트 엔지니어링의 효율성을 높이기 위해 APE, LPO, RSIP/AvR과 같은 자동화된 프롬프트 최적화 도구의 도입을 고려해야 합니다.22  
* **지속적인 평가 및 개선**: LLM 애플리케이션의 성능을 지속적으로 모니터링하고, LLM-as-a-judge와 같은 정교한 평가 방법론을 사용하여 인간의 기대치에 부합하는지 확인하며 반복적으로 개선해야 합니다.1  
* **안전성 및 윤리적 고려**: LLM의 안전 취약성에 대한 인식을 높이고, 윤리적 프롬프팅 원칙을 적용하여 편향을 줄이고 유해한 콘텐츠 생성을 방지해야 합니다.26

**향후 연구 및 발전 방향**

* LLM의 '재귀적 사고' 및 '메타 인지' 능력 강화 연구가 지속될 것입니다. 이는 LLM이 더욱 복잡한 문제를 자율적으로 해결하고 스스로 학습하는 데 필수적입니다.27  
* 멀티모달 RAG 및 에이전트 AI와의 통합을 통해 LLM의 실제 세계 상호작용 능력이 더욱 확장될 것입니다. 이는 LLM이 텍스트를 넘어 다양한 형태의 데이터를 이해하고 처리하며, 실제 환경에서 복잡한 작업을 수행하는 데 기여할 것입니다.14  
* 프롬프트 취약성 문제를 근본적으로 해결하고 LLM의 '견고성'을 높이는 연구가 중요해질 것입니다. 이는 LLM 기반 시스템의 안정성과 신뢰성을 확보하는 데 필수적인 요소입니다.30  
* LLM의 '설명 가능성'과 '투명성'을 높이는 연구는 신뢰성 높은 AI 시스템 구축에 필수적입니다. CoT와 같은 기법을 더욱 발전시켜 LLM의 의사 결정 과정을 명확히 밝히는 연구가 계속될 것입니다.12  
* AI 시스템의 '자율적 학습 및 개선' 능력을 더욱 고도화하는 방향으로 프롬프트 엔지니어링이 발전할 것입니다. 이는 LLM 개발 및 배포의 효율성을 극대화하고, 인간의 개입 없이도 모델이 지속적으로 성능을 향상시키도록 할 것입니다.22

#### **참고 자료**

1. Prompt Engineering for Large Language Models – Business ..., 7월 3, 2025에 액세스, [https://open.ocolearnok.org/aibusinessapplications/chapter/prompt-engineering-for-large-language-models/](https://open.ocolearnok.org/aibusinessapplications/chapter/prompt-engineering-for-large-language-models/)  
2. 26 Prompting Principles for Optimal LLM Output \- Pareto.AI, 7월 3, 2025에 액세스, [https://pareto.ai/blog/26-prompting-principles-for-llms](https://pareto.ai/blog/26-prompting-principles-for-llms)  
3. What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts, 7월 3, 2025에 액세스, [https://arxiv.org/html/2505.13360v1](https://arxiv.org/html/2505.13360v1)  
4. \[2505.13360\] What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/abs/2505.13360](https://arxiv.org/abs/2505.13360)  
5. Zero Shot Prompting vs. Few-Shot Prompting: Techniques and Real-World Applications, 7월 3, 2025에 액세스, [https://www.beam.cloud/blog/prompting-techniques](https://www.beam.cloud/blog/prompting-techniques)  
6. Prompt engineering techniques: Top 5 for 2025 \- K2view, 7월 3, 2025에 액세스, [https://www.k2view.com/blog/prompt-engineering-techniques/](https://www.k2view.com/blog/prompt-engineering-techniques/)  
7. Shot-Based Prompting: Zero-Shot, One-Shot, and Few-Shot Prompting \- Learn Prompting, 7월 3, 2025에 액세스, [https://learnprompting.org/docs/basics/few\_shot](https://learnprompting.org/docs/basics/few_shot)  
8. arXiv:2402.07927v2 \[cs.AI\] 16 Mar 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2402.07927](https://arxiv.org/pdf/2402.07927)  
9. Master Few-Shot Prompting to Improve AI Performance \- Relevance AI, 7월 3, 2025에 액세스, [https://relevanceai.com/prompt-engineering/master-few-shot-prompting-to-improve-ai-performance](https://relevanceai.com/prompt-engineering/master-few-shot-prompting-to-improve-ai-performance)  
10. Few Shot Prompting : Definition, Usage and Example \- Kata.ai's Blog\!, 7월 3, 2025에 액세스, [https://kata.ai/blog/few-shot-prompting-definition-usage-and-example/](https://kata.ai/blog/few-shot-prompting-definition-usage-and-example/)  
11. What is chain of thought (CoT) prompting? | IBM, 7월 3, 2025에 액세스, [https://www.ibm.com/think/topics/chain-of-thoughts](https://www.ibm.com/think/topics/chain-of-thoughts)  
12. Chain-of-thought prompting 101 \- K2view, 7월 3, 2025에 액세스, [https://www.k2view.com/blog/chain-of-thought-prompting/](https://www.k2view.com/blog/chain-of-thought-prompting/)  
13. What is RAG? \- Retrieval-Augmented Generation AI Explained \- AWS, 7월 3, 2025에 액세스, [https://aws.amazon.com/what-is/retrieval-augmented-generation/](https://aws.amazon.com/what-is/retrieval-augmented-generation/)  
14. What is RAG (Retrieval Augmented Generation)? \- Trantor, 7월 3, 2025에 액세스, [https://www.trantorinc.com/blog/what-is-rag-retrieval-augmented-generation](https://www.trantorinc.com/blog/what-is-rag-retrieval-augmented-generation)  
15. Introduction to Self-Criticism Prompting Techniques for LLMs, 7월 3, 2025에 액세스, [https://learnprompting.org/docs/advanced/self\_criticism/introduction](https://learnprompting.org/docs/advanced/self_criticism/introduction)  
16. Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/html/2410.10735v2](https://arxiv.org/html/2410.10735v2)  
17. Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning \- ResearchGate, 7월 3, 2025에 액세스, [https://www.researchgate.net/publication/384929606\_Embedding\_Self-Correction\_as\_an\_Inherent\_Ability\_in\_Large\_Language\_Models\_for\_Enhanced\_Mathematical\_Reasoning](https://www.researchgate.net/publication/384929606_Embedding_Self-Correction_as_an_Inherent_Ability_in_Large_Language_Models_for_Enhanced_Mathematical_Reasoning)  
18. Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning | OpenReview, 7월 3, 2025에 액세스, [https://openreview.net/forum?id=8Dj6OEMj6W](https://openreview.net/forum?id=8Dj6OEMj6W)  
19. Multi-expert Prompting Improves Reliability, Safety and Usefulness ..., 7월 3, 2025에 액세스, [https://aclanthology.org/2024.emnlp-main.1135/](https://aclanthology.org/2024.emnlp-main.1135/)  
20. Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models \- ACL Anthology, 7월 3, 2025에 액세스, [https://aclanthology.org/2024.emnlp-main.1135.pdf](https://aclanthology.org/2024.emnlp-main.1135.pdf)  
21. Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models | OpenReview, 7월 3, 2025에 액세스, [https://openreview.net/forum?id=XRcVKe9SwMw](https://openreview.net/forum?id=XRcVKe9SwMw)  
22. A Complete Guide to Meta Prompting \- PromptHub, 7월 3, 2025에 액세스, [https://www.prompthub.us/blog/a-complete-guide-to-meta-prompting](https://www.prompthub.us/blog/a-complete-guide-to-meta-prompting)  
23. Enhancing LLM Reasoning Capabilities Through Brokered Multi-Expert Reflection, 7월 3, 2025에 액세스, [https://www.researchgate.net/publication/390862251\_Enhancing\_LLM\_Reasoning\_Capabilities\_Through\_Brokered\_Multi-Expert\_Reflection](https://www.researchgate.net/publication/390862251_Enhancing_LLM_Reasoning_Capabilities_Through_Brokered_Multi-Expert_Reflection)  
24. arXiv:2504.20355v1 \[cs.CL\] 29 Apr 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2504.20355](https://arxiv.org/pdf/2504.20355)  
25. Advanced Prompt Engineering Techniques for 2025: Beyond Basic Instructions \- Reddit, 7월 3, 2025에 액세스, [https://www.reddit.com/r/PromptEngineering/comments/1k7jrt7/advanced\_prompt\_engineering\_techniques\_for\_2025/](https://www.reddit.com/r/PromptEngineering/comments/1k7jrt7/advanced_prompt_engineering_techniques_for_2025/)  
26. Advances in LLM Prompting and Model Capabilities: A 2024-2025 Review : r/ClaudeAI, 7월 3, 2025에 액세스, [https://www.reddit.com/r/ClaudeAI/comments/1kijb7i/advances\_in\_llm\_prompting\_and\_model\_capabilities/](https://www.reddit.com/r/ClaudeAI/comments/1kijb7i/advances_in_llm_prompting_and_model_capabilities/)  
27. Unlocking Recursive Thinking of LLMs: Alignment via ... \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2506.06009](https://arxiv.org/pdf/2506.06009)  
28. MODP: Multi Objective Directional Prompting \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/html/2504.18722v1](https://arxiv.org/html/2504.18722v1)  
29. (PDF) MODP: Multi Objective Directional Prompting \- ResearchGate, 7월 3, 2025에 액세스, [https://www.researchgate.net/publication/391247557\_MODP\_Multi\_Objective\_Directional\_Prompting](https://www.researchgate.net/publication/391247557_MODP_Multi_Objective_Directional_Prompting)  
30. arXiv:2504.06969v1 \[cs.CL\] 9 Apr 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2504.06969](https://arxiv.org/pdf/2504.06969)  
31. 20 LLM evaluation benchmarks and how they work \- Evidently AI, 7월 3, 2025에 액세스, [https://www.evidentlyai.com/llm-guide/llm-benchmarks](https://www.evidentlyai.com/llm-guide/llm-benchmarks)  
32. LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide \- Confident AI, 7월 3, 2025에 액세스, [https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)  
33. LLM Evaluation: Frameworks, Metrics, and Best Practices | SuperAnnotate, 7월 3, 2025에 액세스, [https://www.superannotate.com/blog/llm-evaluation-guide](https://www.superannotate.com/blog/llm-evaluation-guide)  
34. arXiv:2503.02756v1 \[cs.CL\] 4 Mar 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2503.02756](https://arxiv.org/pdf/2503.02756)  
35. \[2506.20815\] Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/abs/2506.20815](https://arxiv.org/abs/2506.20815)  
36. arXiv:2502.13422v1 \[cs.CL\] 19 Feb 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2502.13422](https://arxiv.org/pdf/2502.13422)  
37. Decomposed Prompting: Unveiling Multilingual Linguistic Structure Knowledge in English-Centric Large Language Models \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/html/2402.18397v1](https://arxiv.org/html/2402.18397v1)  
38. Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/html/2503.02863v1](https://arxiv.org/html/2503.02863v1)  
39. Two LLMs Debate, Both Are Certain They've Won \- arXiv, 7월 3, 2025에 액세스, [http://arxiv.org/pdf/2505.19184](http://arxiv.org/pdf/2505.19184)  
40. arXiv:2503.16416v1 \[cs.AI\] 20 Mar 2025, 7월 3, 2025에 액세스, [https://arxiv.org/pdf/2503.16416](https://arxiv.org/pdf/2503.16416)  
41. ACL 2025 Main Conference LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts \\faWarningWARNING: This paper contains model outputs that may be considered offensive. \- arXiv, 7월 3, 2025에 액세스, [https://arxiv.org/html/2410.10700v2](https://arxiv.org/html/2410.10700v2)